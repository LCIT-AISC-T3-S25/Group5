{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96491ac-e9d6-41dd-894b-5f6c66fde6ec",
   "metadata": {},
   "source": [
    "## Empirical Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727ba3f-a21a-496a-b4bb-10989884a4e0",
   "metadata": {},
   "source": [
    "### Round 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d94bccbd-cdc9-4c7f-9dfc-f6489dbce4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best CV Accuracy: 0.6872464764523891\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [3, 5],'weights': ['uniform', 'distance'],'metric': ['euclidean']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(n_jobs=-1), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57690544-6165-4f57-9320-20fb8459f306",
   "metadata": {},
   "source": [
    "## üîç Observations ‚Äì Round 1 (KNN with GridSearchCV)\n",
    "\n",
    "### üß™ Model Performance\n",
    "- **Best CV Accuracy**: `68.72%` via GridSearchCV\n",
    "- **Test Accuracy**: `69.29%` ‚Äì Fair baseline, especially considering KNN‚Äôs simplicity and scalability limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d64b2541-dc05-4df9-9b6c-61fb760ffb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = grid.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "y_pred_probs = best_knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76092f8a-0d20-46f3-88a9-b16d9640faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Accuracy: 0.6929\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüîπ Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c662339-b85a-470f-92b9-c3f38b7f9100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Confusion Matrix:\n",
      "[[  808  1073  1004    17   232]\n",
      " [  231 17822  2695    91   770]\n",
      " [  183  2053  7838    26  1106]\n",
      " [    7   161    84    71    13]\n",
      " [   62  1000  1460    17  1175]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüîπ Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43258234-26bd-4500-8a1a-3a11fc9986e1",
   "metadata": {},
   "source": [
    "### üßæ Confusion Matrix Insights\n",
    "- Large confusion between:\n",
    "  - `'Drink'` ‚Üî `'Inside'` and `'Food'`\n",
    "  - `'Menu'` ‚Üî `'Food'` and `'Inside'`\n",
    "  - `'Outside'` misclassified as `'Inside'` and `'Food'`\n",
    "- **High true positives for 'Food'**, but minority classes get heavily confused or ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e245067d-a9c8-4fd9-b61d-d47543e1ebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drink       0.63      0.26      0.37      3134\n",
      "        food       0.81      0.82      0.82     21609\n",
      "      inside       0.60      0.70      0.65     11206\n",
      "        menu       0.32      0.21      0.25       336\n",
      "     outside       0.36      0.32      0.34      3714\n",
      "\n",
      "    accuracy                           0.69     39999\n",
      "   macro avg       0.54      0.46      0.48     39999\n",
      "weighted avg       0.69      0.69      0.68     39999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=list(label_dict.values()))\n",
    "print(\"\\nüîπ Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c904f-571a-46e4-b2f3-11f91adba01d",
   "metadata": {},
   "source": [
    "### üìâ Class-wise Performance\n",
    "- **'Food'** is the top-performing class:\n",
    "  - `Precision: 0.81`, `Recall: 0.82`, `F1-score: 0.82` ‚Äì consistent and strong.\n",
    "- **'Inside'** performs moderately:\n",
    "  - `Recall: 0.70`, `F1-score: 0.65` ‚Äì fairly balanced.\n",
    "- **'Drink'**, **'Menu'**, and **'Outside'** have poor performance:\n",
    "  - 'Drink': `F1-score: 0.37`\n",
    "  - 'Menu': `F1-score: 0.25`\n",
    "  - 'Outside': `F1-score: 0.34`\n",
    "\n",
    "### üìä Advanced Metrics\n",
    "- **Macro F1-score**: `0.48` ‚Äì reflects class imbalance.\n",
    "- **Weighted F1-score**: `0.68` ‚Äì benefits from large 'Food' class performance.\n",
    "- **Macro Precision**: `0.54`, **Macro Recall**: `0.46` ‚Äì suggests room for improvement, particularly on minority classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec1de103-933e-4120-a20d-e2978e97ac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ AUC Scores (per class):\n",
      "Class drink AUC: 0.679\n",
      "Class food AUC: 0.873\n",
      "Class inside AUC: 0.836\n",
      "Class menu AUC: 0.706\n",
      "Class outside AUC: 0.733\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ AUC Scores (per class):\")\n",
    "num_classes = len(label_dict)\n",
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "auc_scores = []\n",
    "for i in range(num_classes):\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test_cat[:, i], y_pred_probs[:, i])\n",
    "        auc_scores.append(auc)\n",
    "        print(f\"Class {label_dict[i]} AUC: {auc:.3f}\")\n",
    "    except Exception:\n",
    "        auc_scores.append(None)\n",
    "        print(f\"Class {label_dict[i]} AUC: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a782ac-82e9-4d6a-af3c-c81ca8b0d954",
   "metadata": {},
   "source": [
    "### üìà AUC per Class\n",
    "- **'Food' and 'Inside'** show strong AUC:\n",
    "  - `Food: 0.873`, `Inside: 0.836`\n",
    "- **'Drink', 'Menu', 'Outside'** have weaker AUCs:\n",
    "  - `Drink: 0.679`, `Menu: 0.706`, `Outside: 0.733`\n",
    "- Indicates good discrimination for dominant classes, but struggles with edge cases and small classes.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Summary ‚Äì Round 1\n",
    "\n",
    "- **KNN with GridSearchCV** provides a solid baseline model with **~69% test accuracy**, outperforming chance but limited in class sensitivity.\n",
    "- **Class imbalance is clearly a major challenge**:\n",
    "  - Minority classes like **'menu'**, **'outside'**, and **'drink'** perform poorly in terms of recall and F1-score.\n",
    "- **Strong reliance on majority class ('food')**, which inflates weighted metrics but masks poor per-class performance.\n",
    "- **AUC scores reveal good potential for ranking/class separation**, especially for 'food' and 'inside'.\n",
    "\n",
    "### ‚úÖ Recommendation\n",
    "- **KNN is sensitive to class imbalance and high-dimensional data** ‚Äì consider switching to tree-based models or neural nets.\n",
    "- If continuing with KNN:\n",
    "  - Try **dimensionality reduction (e.g., PCA)** before fitting\n",
    "  - Implement **SMOTE** or **class-weighted strategies** to balance classes\n",
    "  - Consider **distance-based kernel tuning** or different distance metrics\n",
    "- Use these results as a **baseline** to benchmark future models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8605a-0a37-4f7c-875f-03e827336f2c",
   "metadata": {},
   "source": [
    "## Round 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6954afe0-2c9c-4644-a0e0-0407af63f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pca_knn = None\n",
    "best_pca_acc = 0\n",
    "best_pca_X_test = None\n",
    "best_pca_y_test = None\n",
    "best_pca_y_pred_probs = None\n",
    "best_pca_label_dict = label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e0bd712-5717-436b-b995-9bb1b546f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Components: 50, Accuracy: 0.6883\n",
      "PCA Components: 100, Accuracy: 0.6880\n"
     ]
    }
   ],
   "source": [
    "for n in [50, 100]:\n",
    "    pca = PCA(n_components=n)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, stratify=y_encoded)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    y_pred_probs = knn.predict_proba(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"PCA Components: {n}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "    if acc > best_pca_acc:\n",
    "        best_pca_acc = acc\n",
    "        best_pca_knn = knn\n",
    "        best_pca_X_test = X_test\n",
    "        best_pca_y_test = y_test\n",
    "        best_pca_y_pred_probs = y_pred_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee0dc2-0428-4071-a90f-a049733c30e4",
   "metadata": {},
   "source": [
    "## üîç Observations ‚Äì Round 2 (KNN with PCA)\n",
    "\n",
    "### üß™ Model Performance\n",
    "- **Test Accuracy**: `68.83%`\n",
    "- **PCA Comparison**:\n",
    "  - `50 components`: Accuracy = `68.83%`\n",
    "  - `100 components`: Accuracy = `68.80%`\n",
    "- PCA doesn‚Äôt significantly affect performance ‚Äî suggests intrinsic data structure may not be highly compressible, or KNN is not effectively leveraging reduced dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ffbe83a6-d042-4694-a91f-1ae21380cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_pca_knn.predict(best_pca_X_test)\n",
    "y_pred_probs = best_pca_y_pred_probs\n",
    "y_test = best_pca_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e0e9ee3e-7b79-4f4c-9261-4718f192d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Round 2 ‚Äî Accuracy: 0.6883\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüî∏ Round 2 ‚Äî Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b9a91a9-bdeb-4982-a57c-8b7150a99931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Round 2 ‚Äî Confusion Matrix:\n",
      "[[  783  1279   950     8   114]\n",
      " [  396 18277  2551    30   355]\n",
      " [  324  2646  7568    11   657]\n",
      " [   14   193    80    39    10]\n",
      " [  116  1216  1513     6   863]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüî∏ Round 2 ‚Äî Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c1e3e-b610-4175-890b-742f9455aaa8",
   "metadata": {},
   "source": [
    "### üßæ Confusion Matrix Insights\n",
    "- **'Food'** predictions overwhelm others ‚Äî many samples from other classes (especially `'menu'` and `'outside'`) misclassified as `'food'`.\n",
    "- **'Menu' class struggles most**:\n",
    "  - Out of 336 samples, only ~40 correctly classified.\n",
    "- **'Inside'** class sees improvements in correct predictions, better than Round 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "26d8ca74-1572-4851-87bc-3642cd157f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Round 2 ‚Äî Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drink       0.48      0.25      0.33      3134\n",
      "        food       0.77      0.85      0.81     21609\n",
      "      inside       0.60      0.68      0.63     11206\n",
      "        menu       0.41      0.12      0.18       336\n",
      "     outside       0.43      0.23      0.30      3714\n",
      "\n",
      "    accuracy                           0.69     39999\n",
      "   macro avg       0.54      0.42      0.45     39999\n",
      "weighted avg       0.67      0.69      0.67     39999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=list(label_dict.values()))\n",
    "print(\"\\nüî∏ Round 2 ‚Äî Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a91df-5ddc-461b-b086-d390e130ef4c",
   "metadata": {},
   "source": [
    "### üìâ Class-wise Performance\n",
    "- **'Food'** class continues to dominate:\n",
    "  - `Precision: 0.77`, `Recall: 0.85`, `F1-score: 0.81` ‚Äî slight dip from Round 1 but still strong.\n",
    "- **'Inside'** remains decent:\n",
    "  - `F1-score: 0.63`, up slightly from Round 1.\n",
    "- **'Drink'**, **'Outside'**, and **'Menu'** remain problematic:\n",
    "  - 'Drink': `F1-score: 0.33` (recall dropped to 0.25)\n",
    "  - 'Outside': `F1-score: 0.30`\n",
    "  - 'Menu': `F1-score: 0.18`, recall plummets to 0.12 ‚Äî nearly all menu items misclassified.\n",
    "\n",
    "### üìä Advanced Metrics\n",
    "- **Macro F1-score**: `0.45` ‚Äì consistent with Round 1 (`0.48`)\n",
    "- **Weighted F1-score**: `0.67` ‚Äì slightly lower than Round 1 due to drops in precision for minority classes.\n",
    "- **Macro Recall**: `0.42`, **Macro Precision**: `0.54` ‚Äì unchanged from Round 1, suggesting PCA didn‚Äôt help recover lost recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21fdd9d2-d124-4e73-985f-56c2c6572904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Round 2 ‚Äî AUC Scores (per class):\n",
      "Class drink AUC: 0.676\n",
      "Class food AUC: 0.861\n",
      "Class inside AUC: 0.821\n",
      "Class menu AUC: 0.684\n",
      "Class outside AUC: 0.711\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüî∏ Round 2 ‚Äî AUC Scores (per class):\")\n",
    "y_test_cat = to_categorical(y_test, num_classes=len(label_dict))\n",
    "auc_scores = []\n",
    "for i in range(len(label_dict)):\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test_cat[:, i], y_pred_probs[:, i])\n",
    "        auc_scores.append(auc)\n",
    "        print(f\"Class {label_dict[i]} AUC: {auc:.3f}\")\n",
    "    except Exception:\n",
    "        auc_scores.append(None)\n",
    "        print(f\"Class {label_dict[i]} AUC: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ede78-16ff-4e9a-913b-afb620131be6",
   "metadata": {},
   "source": [
    "### üìà AUC per Class\n",
    "- Slight dip in AUC scores compared to Round 1:\n",
    "  - `'Drink': 0.676` (‚Üì from 0.679)\n",
    "  - `'Food': 0.861` (‚Üì from 0.873)\n",
    "  - `'Inside': 0.821` (‚Üì from 0.836)\n",
    "  - `'Menu': 0.684` (‚Üì from 0.706)\n",
    "  - `'Outside': 0.711` (‚Üì from 0.733)\n",
    "- PCA may have caused subtle degradation in feature separation ability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "223d53dc-1b58-48bb-a473-2b2bd6ec6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Round2'] = {'accuracy': accuracy,'auc_scores': auc_scores,'confusion_matrix': cm}\n",
    "report_dicts['Round2'] = classification_report(y_test, y_pred, target_names=list(label_dict.keys()), output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa785de-c697-47b1-bfbc-d582252b395c",
   "metadata": {},
   "source": [
    "---\n",
    "## üìå Summary ‚Äì Round 2\n",
    "\n",
    "- Applying **PCA before KNN** offers **negligible improvement** ‚Äî same accuracy (`~68.8%`) and slightly lower performance on minority classes.\n",
    "- **'Food'** remains a strong performer, but **other classes suffer from confusion**, particularly 'menu' and 'outside'.\n",
    "- **Recall for minority classes deteriorated**, especially for **'menu'**.\n",
    "- **AUC scores and F1-metrics show general performance stagnation or decline** ‚Äî PCA hasn‚Äôt added discriminative power in this case.\n",
    "\n",
    "### ‚úÖ Recommendation\n",
    "- PCA may not be effective for this dataset + KNN combo:\n",
    "  - **Original high-dimensional features may retain critical class signals**\n",
    "  - **KNN** is sensitive to distance metrics ‚Äî PCA may distort class boundaries\n",
    "- Try:\n",
    "  - **Other dimensionality reduction techniques** (e.g., UMAP, t-SNE for visualization or LDA for supervised reduction)\n",
    "  - **Alternative classifiers** (Random Forest, Gradient Boosting, or Neural Networks)\n",
    "  - **Class rebalancing techniques** or custom distance metrics that weight minority classes more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee65ea3-9875-48b2-b295-68e54f09614d",
   "metadata": {},
   "source": [
    "## Round 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "50785fa5-fb74-460e-8ab7-3f8ee9c6ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {'Standard': StandardScaler(),'MinMax': MinMaxScaler(),'Robust': RobustScaler()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "097ddf42-5ae4-4b18-a2c3-2fb33e5d7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scaler_name = None\n",
    "best_scaler_knn = None\n",
    "best_scaler_X_test = None\n",
    "best_scaler_y_test = None\n",
    "best_scaler_y_pred_probs = None\n",
    "best_scaler_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0b028f14-7a10-4d1c-8a6d-e83000914943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler, Accuracy: 0.6876\n",
      "MinMax Scaler, Accuracy: 0.6898\n",
      "Robust Scaler, Accuracy: 0.6868\n"
     ]
    }
   ],
   "source": [
    "for name, scaler in scalers.items():\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=100)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, stratify=y_encoded)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    y_pred_probs = knn.predict_proba(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Scaler, Accuracy: {acc:.4f}\")\n",
    "\n",
    "    if acc > best_scaler_acc:\n",
    "        best_scaler_acc = acc\n",
    "        best_scaler_name = name\n",
    "        best_scaler_knn = knn\n",
    "        best_scaler_X_test = X_test\n",
    "        best_scaler_y_test = y_test\n",
    "        best_scaler_y_pred_probs = y_pred_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09c762-dbe8-455a-ae5e-04abb88492ed",
   "metadata": {},
   "source": [
    "## üîç Observations ‚Äì Round 3 (KNN with Scaling Techniques)\n",
    "\n",
    "### üß™ Model Performance\n",
    "- **Best Scaler**: `MinMaxScaler` with **Accuracy = 68.98%**\n",
    "- **Other Scalers**:\n",
    "  - StandardScaler: `68.76%`\n",
    "  - RobustScaler: `68.68%`\n",
    "- All scalers yielded similar performance, but **MinMaxScaler slightly outperformed** in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "61e066a0-652d-432d-8b04-abcf80197fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_scaler_knn.predict(best_scaler_X_test)\n",
    "y_pred_probs = best_scaler_y_pred_probs\n",
    "y_test = best_scaler_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eedc8998-2ca3-4ed5-871a-3e41df7d2894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Round 3 ‚Äî Best Scaler: MinMax\n",
      "üî∏ Accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüî∏ Round 3 ‚Äî Best Scaler: {best_scaler_name}\")\n",
    "print(f\"üî∏ Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d5427bf3-b3d9-4f8b-ae95-85905262b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Confusion Matrix:\n",
      "[[  795  1191   984     7   157]\n",
      " [  374 18086  2624    44   481]\n",
      " [  296  2453  7676    27   754]\n",
      " [   15   164    96    54     7]\n",
      " [   95  1144  1485     9   981]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüî∏ Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4803fe-0d5f-4826-b2ec-a84a5c6bc427",
   "metadata": {},
   "source": [
    "### üßæ Confusion Matrix Insights\n",
    "- **'Food' continues to absorb misclassifications** from most other classes, especially 'menu' and 'outside'.\n",
    "- **'Menu' classification slightly improved** compared to Round 2, but recall remains very low (`0.16`).\n",
    "- **'Inside' performance holds steady**, reflecting decent model sensitivity to indoor content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c5b9c512-8a31-4b4d-8cee-22ccd4f6e89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drink       0.50      0.25      0.34      3134\n",
      "        food       0.79      0.84      0.81     21609\n",
      "      inside       0.60      0.68      0.64     11206\n",
      "        menu       0.38      0.16      0.23       336\n",
      "     outside       0.41      0.26      0.32      3714\n",
      "\n",
      "    accuracy                           0.69     39999\n",
      "   macro avg       0.54      0.44      0.47     39999\n",
      "weighted avg       0.67      0.69      0.67     39999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=list(label_dict.values()))\n",
    "print(\"\\nüî∏ Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b8b26-9616-4cb4-a02e-9517b26d36d9",
   "metadata": {},
   "source": [
    "### üìâ Class-wise Performance\n",
    "- **'Food'** continues to dominate:\n",
    "  - `Precision: 0.79`, `Recall: 0.84`, `F1-score: 0.81`\n",
    "- **'Inside'** remains consistent:\n",
    "  - `F1-score: 0.64`, comparable to Round 2\n",
    "- **'Drink'**, **'Menu'**, and **'Outside'** still underperform:\n",
    "  - 'Drink': `F1-score: 0.34`\n",
    "  - 'Outside': `F1-score: 0.32`\n",
    "  - 'Menu': `F1-score: 0.23` ‚Äì slight gain from Round 2 but still very weak\n",
    "\n",
    "### üìä Advanced Metrics\n",
    "- **Macro F1-score**: `0.47` ‚Äì slight improvement over Round 2\n",
    "- **Weighted F1-score**: `0.67` ‚Äì consistent across all rounds\n",
    "- **Macro Recall**: `0.44`, **Macro Precision**: `0.54` ‚Äì same as Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "949455b3-2655-4c0e-ac4c-c091efbcb272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ AUC Scores (per class):\n",
      "Class drink AUC: 0.673\n",
      "Class food AUC: 0.861\n",
      "Class inside AUC: 0.822\n",
      "Class menu AUC: 0.707\n",
      "Class outside AUC: 0.723\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüî∏ AUC Scores (per class):\")\n",
    "y_test_cat = to_categorical(y_test, num_classes=len(label_dict))\n",
    "auc_scores = []\n",
    "for i in range(len(label_dict)):\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test_cat[:, i], y_pred_probs[:, i])\n",
    "        auc_scores.append(auc)\n",
    "        print(f\"Class {label_dict[i]} AUC: {auc:.3f}\")\n",
    "    except Exception:\n",
    "        auc_scores.append(None)\n",
    "        print(f\"Class {label_dict[i]} AUC: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d23fc-f86a-485c-828e-6202ba0edd0b",
   "metadata": {},
   "source": [
    "### üìà AUC per Class\n",
    "- Very similar to Round 2:\n",
    "  - `'Drink': 0.673`, `'Food': 0.861`, `'Inside': 0.822`, `'Menu': 0.707`, `'Outside': 0.723`\n",
    "- **No meaningful improvement in class separation** from scaling ‚Äì AUC scores nearly identical.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "07b6f304-63b1-4156-87a6-e4bae32e9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Round3'] = {'accuracy': accuracy,'auc_scores': auc_scores,'confusion_matrix': cm,'best_scaler': best_scaler_name}\n",
    "report_dicts['Round3'] = classification_report(y_test, y_pred, target_names=list(label_dict.keys()), output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ea721-e3c1-45da-9ae2-9b619ebdff03",
   "metadata": {},
   "source": [
    "## üìå Summary ‚Äì Round 3\n",
    "\n",
    "- **MinMaxScaler** produced the best results among the scaling methods, but **improvements were minimal** (`+0.1‚Äì0.2%`).\n",
    "- **No breakthrough in addressing class imbalance or minority class confusion**.\n",
    "- AUC and F1-scores are largely unchanged from Round 2, suggesting **scaling has limited impact on KNN performance in this context**.\n",
    "- **'Food' class performance props up overall metrics**, while 'drink', 'outside', and 'menu' continue to perform poorly.\n",
    "\n",
    "### ‚úÖ Recommendation\n",
    "- Scaling has **marginal benefits** for KNN in this scenario.\n",
    "- Consider focusing on:\n",
    "  - **Model type upgrades** (e.g., SVMs, ensemble models)\n",
    "  - **Feature engineering** to highlight class-discriminative properties\n",
    "  - **Data rebalancing techniques** (e.g., SMOTE) or **class-specific tuning**\n",
    "- Use this round as a confirmation that **data scaling alone cannot resolve class-level performance gaps**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
