{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad1e6f3-3de8-458c-9fee-f8a7db5c3976",
   "metadata": {},
   "source": [
    "# Deep Unidirectional RNN Model using TF-IDF with unigram+bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ab89f9e-d8fd-4535-a738-f28b5cf94237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, SimpleRNN\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8acd2442-4d68-433e-8c1b-f87837c067af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1ad4d5f-fad0-4317-b5c2-59a6e34f96e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF features...\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF with unigram + bigram\n",
    "print(\"Creating TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=3000)\n",
    "X_train_tfidf = tfidf.fit_transform(df_train['processed_tweet'])\n",
    "X_test_tfidf = tfidf.transform(df_test['processed_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfce06d1-b91e-48e1-898b-9e6aed611e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dense arrays\n",
    "X_train = X_train_tfidf.astype('float32').toarray()\n",
    "X_test = X_test_tfidf.astype('float32').toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e30de2c3-b55e-4eb0-86b1-d2d9a90d9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 30, 100))\n",
    "X_test = X_test.reshape((X_test.shape[0], 30, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59f76df8-fafc-4325-b5a1-fa1a720d9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment_label'])\n",
    "y_test = le.transform(df_test['sentiment_label'])\n",
    "num_classes = len(le.classes_)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d06c4a8b-6abf-406d-9fdd-62c2ea70305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"deep_unirnn_tfidf.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "362c373b-e134-4875-a34b-ecab1e1c5311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF features...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, SimpleRNN, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# TF-IDF vectorization\n",
    "print(\"Creating TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(df_train['processed_tweet'])\n",
    "X_test_tfidf = tfidf.transform(df_test['processed_tweet'])\n",
    "\n",
    "# Convert to 3D arrays (30x100 shape)\n",
    "X_train = X_train_tfidf.astype('float32').toarray().reshape((-1, 30, 100))\n",
    "X_test = X_test_tfidf.astype('float32').toarray().reshape((-1, 30, 100))\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment_label'])\n",
    "y_test = le.transform(df_test['sentiment_label'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6616c0f0-ca1d-40e5-84fe-93c16d83df64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 1 Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 17ms/step - accuracy: 0.5955 - loss: 1.0999 - val_accuracy: 0.6452 - val_loss: 0.9509 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.6421 - loss: 0.9660 - val_accuracy: 0.6625 - val_loss: 0.9141 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.6519 - loss: 0.9438 - val_accuracy: 0.6631 - val_loss: 0.9122 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 14ms/step - accuracy: 0.6565 - loss: 0.9349 - val_accuracy: 0.6610 - val_loss: 0.9175 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.6589 - loss: 0.9265 - val_accuracy: 0.6679 - val_loss: 0.9052 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 13ms/step - accuracy: 0.6615 - loss: 0.9221 - val_accuracy: 0.6703 - val_loss: 0.9004 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 14ms/step - accuracy: 0.6646 - loss: 0.9155 - val_accuracy: 0.6745 - val_loss: 0.8881 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 15ms/step - accuracy: 0.6673 - loss: 0.9095 - val_accuracy: 0.6705 - val_loss: 0.9012 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m4511/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6676 - loss: 0.9065\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 14ms/step - accuracy: 0.6676 - loss: 0.9065 - val_accuracy: 0.6710 - val_loss: 0.8975 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.6835 - loss: 0.8740 - val_accuracy: 0.6951 - val_loss: 0.8451 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.6908 - loss: 0.8583 - val_accuracy: 0.6977 - val_loss: 0.8414 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 16ms/step - accuracy: 0.6905 - loss: 0.8596 - val_accuracy: 0.6999 - val_loss: 0.8366 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 16ms/step - accuracy: 0.6937 - loss: 0.8521 - val_accuracy: 0.6998 - val_loss: 0.8338 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 15ms/step - accuracy: 0.6925 - loss: 0.8536 - val_accuracy: 0.7004 - val_loss: 0.8334 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 15ms/step - accuracy: 0.6948 - loss: 0.8521 - val_accuracy: 0.7013 - val_loss: 0.8330 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 14ms/step - accuracy: 0.6968 - loss: 0.8485 - val_accuracy: 0.6990 - val_loss: 0.8358 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 15ms/step - accuracy: 0.6980 - loss: 0.8449 - val_accuracy: 0.7021 - val_loss: 0.8299 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 14ms/step - accuracy: 0.6983 - loss: 0.8432 - val_accuracy: 0.7007 - val_loss: 0.8310 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 14ms/step - accuracy: 0.6965 - loss: 0.8468 - val_accuracy: 0.7041 - val_loss: 0.8287 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.6966 - loss: 0.8467 - val_accuracy: 0.6998 - val_loss: 0.8340 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Iteration 1 Model...\")\n",
    "\n",
    "model1 = Sequential([\n",
    "    Input(shape=(30, 100)),\n",
    "    SimpleRNN(128, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    SimpleRNN(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "history1 = model1.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffca55db-58fe-41eb-bf9c-3a2658a966b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2821/2821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step\n",
      "AUC = 0.8711\n",
      "F1 Score for Positive = 0.3994\n",
      "F1 Score for Negative = 0.3189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict probabilities and labels using Iteration 1 model\n",
    "y_pred_prob = model1.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# AUC (macro)\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "except:\n",
    "    auc = \"Error calculating AUC\"\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "# Assuming 2 classes: le.classes_[0] = Negative, le.classes_[1] = Positive\n",
    "f1_negative = report[le.classes_[0]][\"f1-score\"]\n",
    "f1_positive = report[le.classes_[1]][\"f1-score\"]\n",
    "\n",
    "# Output\n",
    "print(f\"AUC = {auc:.4f}\" if isinstance(auc, float) else f\"AUC = {auc}\")\n",
    "print(f\"F1 Score for Positive = {f1_positive:.4f}\")\n",
    "print(f\"F1 Score for Negative = {f1_negative:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fa5ed3a-40da-41df-a3bd-5518f3906ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy (Test): 0.7142\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"✅ Accuracy (Test): {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c68e74d4-a282-4b1a-a476-6d1b6b9ca15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 2 Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 39ms/step - accuracy: 0.5757 - loss: 1.1730 - val_accuracy: 0.6043 - val_loss: 1.0746 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 37ms/step - accuracy: 0.6131 - loss: 1.0556 - val_accuracy: 0.6188 - val_loss: 1.0351 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 37ms/step - accuracy: 0.6265 - loss: 1.0215 - val_accuracy: 0.6327 - val_loss: 1.0060 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 37ms/step - accuracy: 0.6415 - loss: 0.9869 - val_accuracy: 0.6364 - val_loss: 0.9824 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 38ms/step - accuracy: 0.6498 - loss: 0.9651 - val_accuracy: 0.6572 - val_loss: 0.9388 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 37ms/step - accuracy: 0.6590 - loss: 0.9406 - val_accuracy: 0.6584 - val_loss: 0.9318 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 37ms/step - accuracy: 0.6662 - loss: 0.9226 - val_accuracy: 0.6735 - val_loss: 0.9022 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 37ms/step - accuracy: 0.6767 - loss: 0.8990 - val_accuracy: 0.6704 - val_loss: 0.9052 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 37ms/step - accuracy: 0.6798 - loss: 0.8871 - val_accuracy: 0.6845 - val_loss: 0.8779 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 37ms/step - accuracy: 0.6854 - loss: 0.8760 - val_accuracy: 0.6812 - val_loss: 0.8876 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 37ms/step - accuracy: 0.6895 - loss: 0.8627 - val_accuracy: 0.6895 - val_loss: 0.8623 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 38ms/step - accuracy: 0.6955 - loss: 0.8490 - val_accuracy: 0.6916 - val_loss: 0.8584 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 39ms/step - accuracy: 0.6992 - loss: 0.8389 - val_accuracy: 0.6844 - val_loss: 0.8688 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 38ms/step - accuracy: 0.7022 - loss: 0.8321 - val_accuracy: 0.6958 - val_loss: 0.8434 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 37ms/step - accuracy: 0.7065 - loss: 0.8218 - val_accuracy: 0.7037 - val_loss: 0.8262 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 38ms/step - accuracy: 0.7110 - loss: 0.8108 - val_accuracy: 0.6954 - val_loss: 0.8464 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m4513/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7123 - loss: 0.8052\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 37ms/step - accuracy: 0.7123 - loss: 0.8052 - val_accuracy: 0.6960 - val_loss: 0.8596 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 37ms/step - accuracy: 0.7215 - loss: 0.7823 - val_accuracy: 0.7132 - val_loss: 0.8128 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 37ms/step - accuracy: 0.7257 - loss: 0.7719 - val_accuracy: 0.7113 - val_loss: 0.8144 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 37ms/step - accuracy: 0.7276 - loss: 0.7662 - val_accuracy: 0.7121 - val_loss: 0.8095 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Iteration 2 Model...\")\n",
    "\n",
    "model2 = Sequential([\n",
    "    Input(shape=(30, 100)),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "# Remove EarlyStopping to ensure full 20 epochs\n",
    "history2 = model2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[reduce_lr],  # Optional: keep ReduceLROnPlateau if helpful\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d74bfde-149f-41af-9001-c1cfb1be6aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2821/2821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step\n",
      "AUC = 0.8538\n",
      "F1 Score for Positive = 0.3573\n",
      "F1 Score for Negative = 0.2774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict probabilities and labels using Iteration 1 model\n",
    "y_pred_prob = model1.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# AUC (macro)\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "except:\n",
    "    auc = \"Error calculating AUC\"\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "# Assuming 2 classes: le.classes_[0] = Negative, le.classes_[1] = Positive\n",
    "f1_negative = report[le.classes_[0]][\"f1-score\"]\n",
    "f1_positive = report[le.classes_[1]][\"f1-score\"]\n",
    "\n",
    "# Output\n",
    "print(f\"AUC = {auc:.4f}\" if isinstance(auc, float) else f\"AUC = {auc}\")\n",
    "print(f\"F1 Score for Positive = {f1_positive:.4f}\")\n",
    "print(f\"F1 Score for Negative = {f1_negative:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf023629-e832-40b3-9cff-671b82079bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy (Test): 0.7142\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"✅ Accuracy (Test): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b635926-c701-4cb1-855d-4d01f37354db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Improved Iteration 1 Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 66ms/step - accuracy: 0.5264 - loss: 1.3644 - val_accuracy: 0.5926 - val_loss: 1.2120 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 67ms/step - accuracy: 0.5900 - loss: 1.2218 - val_accuracy: 0.5789 - val_loss: 1.2251 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 69ms/step - accuracy: 0.6008 - loss: 1.1913 - val_accuracy: 0.6159 - val_loss: 1.1709 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 66ms/step - accuracy: 0.6136 - loss: 1.1673 - val_accuracy: 0.6289 - val_loss: 1.1371 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 67ms/step - accuracy: 0.6218 - loss: 1.1517 - val_accuracy: 0.6389 - val_loss: 1.1167 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 67ms/step - accuracy: 0.6305 - loss: 1.1371 - val_accuracy: 0.6367 - val_loss: 1.1260 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 68ms/step - accuracy: 0.6360 - loss: 1.1280 - val_accuracy: 0.6347 - val_loss: 1.1135 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 68ms/step - accuracy: 0.6409 - loss: 1.1174 - val_accuracy: 0.6508 - val_loss: 1.1043 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 69ms/step - accuracy: 0.6444 - loss: 1.1094 - val_accuracy: 0.6565 - val_loss: 1.0858 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 69ms/step - accuracy: 0.6473 - loss: 1.1038 - val_accuracy: 0.6612 - val_loss: 1.0735 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 69ms/step - accuracy: 0.6513 - loss: 1.0978 - val_accuracy: 0.6597 - val_loss: 1.0789 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 69ms/step - accuracy: 0.6529 - loss: 1.0932 - val_accuracy: 0.6645 - val_loss: 1.0689 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 70ms/step - accuracy: 0.6571 - loss: 1.0871 - val_accuracy: 0.6696 - val_loss: 1.0629 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 70ms/step - accuracy: 0.6575 - loss: 1.0822 - val_accuracy: 0.6614 - val_loss: 1.0691 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m4513/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6592 - loss: 1.0802\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 71ms/step - accuracy: 0.6592 - loss: 1.0802 - val_accuracy: 0.6693 - val_loss: 1.0660 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 72ms/step - accuracy: 0.6645 - loss: 1.0708 - val_accuracy: 0.6778 - val_loss: 1.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 72ms/step - accuracy: 0.6684 - loss: 1.0635 - val_accuracy: 0.6791 - val_loss: 1.0389 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 73ms/step - accuracy: 0.6719 - loss: 1.0581 - val_accuracy: 0.6746 - val_loss: 1.0587 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m4513/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6721 - loss: 1.0576\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 72ms/step - accuracy: 0.6721 - loss: 1.0576 - val_accuracy: 0.6793 - val_loss: 1.0435 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m4514/4514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 73ms/step - accuracy: 0.6739 - loss: 1.0524 - val_accuracy: 0.6835 - val_loss: 1.0316 - learning_rate: 2.5000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ======= Load and Prepare Data =======\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# TF-IDF vectorization (improved)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(df_train['processed_tweet'])\n",
    "X_test_tfidf = tfidf.transform(df_test['processed_tweet'])\n",
    "\n",
    "X_train = X_train_tfidf.astype('float32').toarray().reshape((-1, 50, 100))\n",
    "X_test = X_test_tfidf.astype('float32').toarray().reshape((-1, 50, 100))\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment_label'])\n",
    "y_test = le.transform(df_test['sentiment_label'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# ======= Callbacks =======\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1)\n",
    "\n",
    "# ======= Build Model =======\n",
    "print(\"Training Improved Iteration 1 Model...\")\n",
    "\n",
    "model1 = Sequential([\n",
    "    Input(shape=(50, 100)),\n",
    "    LSTM(128, return_sequences=True, recurrent_dropout=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, recurrent_dropout=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with label smoothing\n",
    "loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "model1.compile(loss=loss_fn, optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history1 = model1.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save\n",
    "model1.save(\"improved_iteration1_lstm_tfidf.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "381d7c5c-a4c3-46a7-8527-8ecbc27ce214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy (Test): 0.7142\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"✅ Accuracy (Test): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b28d4abf-8dd6-4339-9d3e-4b8c0e8572dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 2 Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 72ms/step - accuracy: 0.5757 - loss: 1.2559 - val_accuracy: 0.6136 - val_loss: 1.1674 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 72ms/step - accuracy: 0.6119 - loss: 1.1732 - val_accuracy: 0.6306 - val_loss: 1.1302 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 78ms/step - accuracy: 0.6270 - loss: 1.1441 - val_accuracy: 0.6468 - val_loss: 1.1041 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 78ms/step - accuracy: 0.6367 - loss: 1.1264 - val_accuracy: 0.6510 - val_loss: 1.1098 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6441 - loss: 1.1151\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 77ms/step - accuracy: 0.6441 - loss: 1.1151 - val_accuracy: 0.6471 - val_loss: 1.1046 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 75ms/step - accuracy: 0.6564 - loss: 1.0890 - val_accuracy: 0.6698 - val_loss: 1.0598 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 73ms/step - accuracy: 0.6602 - loss: 1.0790 - val_accuracy: 0.6738 - val_loss: 1.0523 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 74ms/step - accuracy: 0.6651 - loss: 1.0713 - val_accuracy: 0.6709 - val_loss: 1.0591 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 75ms/step - accuracy: 0.6695 - loss: 1.0650 - val_accuracy: 0.6783 - val_loss: 1.0469 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 78ms/step - accuracy: 0.6721 - loss: 1.0595 - val_accuracy: 0.6795 - val_loss: 1.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 78ms/step - accuracy: 0.6743 - loss: 1.0562 - val_accuracy: 0.6803 - val_loss: 1.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 76ms/step - accuracy: 0.6755 - loss: 1.0522 - val_accuracy: 0.6833 - val_loss: 1.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 76ms/step - accuracy: 0.6778 - loss: 1.0492 - val_accuracy: 0.6846 - val_loss: 1.0338 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 77ms/step - accuracy: 0.6812 - loss: 1.0432 - val_accuracy: 0.6863 - val_loss: 1.0327 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 78ms/step - accuracy: 0.6820 - loss: 1.0405 - val_accuracy: 0.6891 - val_loss: 1.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 78ms/step - accuracy: 0.6839 - loss: 1.0360 - val_accuracy: 0.6864 - val_loss: 1.0301 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6835 - loss: 1.0366\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m715s\u001b[0m 79ms/step - accuracy: 0.6835 - loss: 1.0366 - val_accuracy: 0.6875 - val_loss: 1.0241 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 81ms/step - accuracy: 0.6888 - loss: 1.0267 - val_accuracy: 0.6917 - val_loss: 1.0152 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 80ms/step - accuracy: 0.6922 - loss: 1.0212 - val_accuracy: 0.6933 - val_loss: 1.0128 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m9027/9027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 83ms/step - accuracy: 0.6913 - loss: 1.0204 - val_accuracy: 0.6946 - val_loss: 1.0146 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# =================== IMPORTS ===================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# =================== DATA PREPROCESSING ===================\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# TF-IDF Vectorization (Improved)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(df_train['processed_tweet'])\n",
    "X_test_tfidf = tfidf.transform(df_test['processed_tweet'])\n",
    "\n",
    "# Convert to arrays and reshape to (samples, 50, 100)\n",
    "X_train = X_train_tfidf.astype('float32').toarray().reshape((-1, 50, 100))\n",
    "X_test = X_test_tfidf.astype('float32').toarray().reshape((-1, 50, 100))\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment_label'])\n",
    "y_test = le.transform(df_test['sentiment_label'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# =================== CALLBACKS ===================\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1)\n",
    "\n",
    "# =================== BUILD MODEL ===================\n",
    "print(\"Training Iteration 2 Model...\")\n",
    "\n",
    "model2 = Sequential([\n",
    "    Input(shape=(50, 100)),\n",
    "    Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.2)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(64, recurrent_dropout=0.2)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with Label Smoothing\n",
    "loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "model2.compile(optimizer=Adam(0.001), loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# =================== TRAIN ===================\n",
    "history2 = model2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=32,  # smaller batch size for more updates\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4ef1151-b1cb-4d47-9791-b6d5664e7980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy (Test): 0.7142\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"✅ Accuracy (Test): {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
