{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74457c0e-690c-4ead-84a5-207bc022a3c9",
   "metadata": {},
   "source": [
    "# Single Layer Unidirectional LSTM Model using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a7a552-60eb-424a-b467-707ea37273e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, SpatialDropout1D, Embedding, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56ddf46-e0ce-4812-b867-d1ceaabe3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349e4f71-d515-4b0f-b55d-8bc43ab0fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d3b09b-ae68-4b22-9004-897c51a4c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [tweet.split() for tweet in pd.concat([df_train, df_test])['processed_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b1e1cb-7717-4039-837c-6b3223d1cf10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4, sg=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1ea8fd-0168-4ab7-bc59-134af186d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "LSTM_UNITS = 128\n",
    "DENSE_UNITS = 64\n",
    "DROPOUT_RATE = 0.3\n",
    "RECURRENT_DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe0fb20-6d9e-44f6-b8bc-bd291c28db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df_train['processed_tweet'])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1e4d4b-451f-4ab4-b508-ef52bb21f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((min(30000, len(word_index))+1, 200))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < 30000 and word in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f181ac6b-de60-4f13-bb26-072cd3ac2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenizer.texts_to_sequences(df_train['processed_tweet']), maxlen=120, padding='post', truncating='post')\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(df_test['processed_tweet']), maxlen=120, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "986bf299-1ec7-4040-b2a0-74fd4866fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment_label'])\n",
    "y_test = le.transform(df_test['sentiment_label'])\n",
    "y_train = pd.get_dummies(y_train).values\n",
    "y_test = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "566ff15b-b2a2-4532-b024-cd9d7a2ecd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('Bidirectional GRU.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c130df-37f2-45b1-b140-49c58077b506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [02h 29m 46s]\n",
      "val_accuracy: 0.7457984089851379\n",
      "\n",
      "Best val_accuracy So Far: 0.7457984089851379\n",
      "Total elapsed time: 02h 29m 46s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "192               |64                |gru_units\n",
      "0.3               |0.2               |dropout_rate\n",
      "0.0020249         |0.004075          |l2_reg\n",
      "0.001             |0.001             |learning_rate\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1411/1411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2957s\u001b[0m 2s/step - accuracy: 0.6178 - loss: 1.0468 - val_accuracy: 0.6933 - val_loss: 0.8443\n",
      "Epoch 2/10\n",
      "\u001b[1m 879/1411\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19:43\u001b[0m 2s/step - accuracy: 0.7004 - loss: 0.8263"
     ]
    }
   ],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dropout, Dense\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Embedding layer with pretrained weights\n",
    "    model.add(Embedding(input_dim=min(30000, len(word_index))+1, \n",
    "                     output_dim=200,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=120,\n",
    "                     trainable=False))\n",
    "    \n",
    "    # Bidirectional GRU layer\n",
    "    model.add(Bidirectional(GRU(units=hp.Int('gru_units', 64, 256, step=64), \n",
    "                        return_sequences=False)))\n",
    "    \n",
    "    model.add(Dropout(hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer for 5 classes\n",
    "    model.add(Dense(5, activation='softmax', \n",
    "               kernel_regularizer=l2(hp.Float('l2_reg', 1e-5, 1e-2, sampling='log'))))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 5e-4, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Initialize tuner\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='sentiment_analysis'\n",
    ")\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Start hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(X_test, y_test),\n",
    "             callbacks=[early_stopping],\n",
    "             batch_size=256)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('best_bidirectional_gru_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
